{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoYF82jKBWdxS5mFKM+Nbr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eshita781996/Pyspark_functions/blob/main/PysparkFunction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TnQ8c2duAxWs"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "!pip -q install findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages io.delta:delta-core_2.12:0.7.0 --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog pyspark-shell'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "BA0w_j_KBCIu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "spark = SparkSession.builder.appName('delta_session').getOrCreate()"
      ],
      "metadata": {
        "id": "_lCwrQwzBFe3"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employees_delta_df = spark.createDataFrame([(2, ' Peter# ', 'Melbourne!', 55000.00),(5, '  Jessie*', '**Brisbane', 42000.00)],\n",
        "                                           schema='emp_id int,emp_name string,emp_city string,emp_salary float')"
      ],
      "metadata": {
        "id": "aBauuEJXBKq2"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def removejunkcharcter(employees_delta_df):\n",
        "  for col in employees_delta_df.dtypes:\n",
        "    employees_delta_df = employees_delta_df.withColumn(col[0], regexp_replace(col[0], '[^a-zA-Z0-9]', ''))\n",
        "  return employees_delta_df"
      ],
      "metadata": {
        "id": "aeAzQ6nBBtJM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def renamecolumn(employees_delta_df,rename_dict):\n",
        "  for i in rename_dict:\n",
        "    employees_delta_df = employees_delta_df.withColumnRenamed(i,rename_dict[i])\n",
        "  return employees_delta_df"
      ],
      "metadata": {
        "id": "VcHPivsBCvA0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dropcolumn(employees_delta_df,drop_cols):\n",
        "  for i in drop_cols:\n",
        "    employees_delta_df = employees_delta_df.drop(i)\n",
        "  return employees_delta_df"
      ],
      "metadata": {
        "id": "stSCd3NYDcLD"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trimcolumns(df):\n",
        "  for colname in df.columns:\n",
        "    df = df.withColumn(colname,trim(df[colname]))\n",
        "  return df"
      ],
      "metadata": {
        "id": "BtgIXnigIJnH"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employees_delta_df.show()\n",
        "df = removejunkcharcter(employees_delta_df)\n",
        "rename_dict = {'emp_id':'employee_id','emp_name':'employee_name','emp_city':'employee_city','emp_salary':'employee_salary'}\n",
        "df_rename = renamecolumn(df,rename_dict)\n",
        "drop_cols = ['employee_city']\n",
        "df_drop = dropcolumn(df_rename,drop_cols)\n",
        "df = trimcolumns(df_drop)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm1pN3-dBz0U",
        "outputId": "97401764-d893-4b3d-f129-2912c6d69eda"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+----------+----------+\n",
            "|emp_id| emp_name|  emp_city|emp_salary|\n",
            "+------+---------+----------+----------+\n",
            "|     2|  Peter# |Melbourne!|   55000.0|\n",
            "|     5|  Jessie*|**Brisbane|   42000.0|\n",
            "+------+---------+----------+----------+\n",
            "\n",
            "+-----------+-------------+---------------+\n",
            "|employee_id|employee_name|employee_salary|\n",
            "+-----------+-------------+---------------+\n",
            "|          2|        Peter|         550000|\n",
            "|          5|       Jessie|         420000|\n",
            "+-----------+-------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CxfxajfQB1oc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}