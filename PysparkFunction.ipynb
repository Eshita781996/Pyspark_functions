{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3J8xqMcuI+rZ93tcqFIlA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eshita781996/Pyspark_functions/blob/main/PysparkFunction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TnQ8c2duAxWs"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "!pip -q install findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages io.delta:delta-core_2.12:0.7.0 --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog pyspark-shell'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "BA0w_j_KBCIu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "spark = SparkSession.builder.appName('delta_session').getOrCreate()"
      ],
      "metadata": {
        "id": "_lCwrQwzBFe3"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "employees_delta_df = spark.createDataFrame([(2, ' Peter# ', 'Melbourne!', 55000.00),(5, '  Jessie*', '**Brisbane', 42000.00)],\n",
        "                                           schema='emp_id int,emp_name string,emp_city string,emp_salary float')"
      ],
      "metadata": {
        "id": "aBauuEJXBKq2"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def removejunkcharcter(employees_delta_df):\n",
        "  for col in employees_delta_df.dtypes:\n",
        "    employees_delta_df = employees_delta_df.withColumn(col[0], regexp_replace(col[0], '[^a-zA-Z0-9]', ''))\n",
        "  return employees_delta_df"
      ],
      "metadata": {
        "id": "aeAzQ6nBBtJM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def renamecolumn(employees_delta_df,rename_dict):\n",
        "  for i in rename_dict:\n",
        "    employees_delta_df = employees_delta_df.withColumnRenamed(i,rename_dict[i])\n",
        "  return employees_delta_df"
      ],
      "metadata": {
        "id": "VcHPivsBCvA0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dropcolumn(employees_delta_df,drop_cols):\n",
        "  for i in drop_cols:\n",
        "    employees_delta_df = employees_delta_df.drop(i)\n",
        "  return employees_delta_df"
      ],
      "metadata": {
        "id": "stSCd3NYDcLD"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trimcolumns(df):\n",
        "  for colname in df.columns:\n",
        "    df = df.withColumn(colname,trim(df[colname]))\n",
        "  return df"
      ],
      "metadata": {
        "id": "BtgIXnigIJnH"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intersection(lst1, lst2):\n",
        "    temp = set(lst2)\n",
        "    lst3 = [value for value in lst1 if value not in temp]\n",
        "    return lst3"
      ],
      "metadata": {
        "id": "bfS0ehYfRBtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createhashkeys(df,key_columns,data_columns):\n",
        "  df = df.withColumn(\"key_hash\", sha2(concat_ws(\"||\", *key_columns), 256)).withColumn(\"data_hash\", sha2(concat_ws(\"||\", *data_columns), 256))\n",
        "  return df"
      ],
      "metadata": {
        "id": "k6GyKSj5KEL_"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = removejunkcharcter(employees_delta_df)\n",
        "rename_dict = {'emp_id':'employee_id','emp_name':'employee_name','emp_city':'employee_city','emp_salary':'employee_salary'}\n",
        "df_rename = renamecolumn(df,rename_dict)\n",
        "#drop_cols = ['employee_city']\n",
        "#df_drop = dropcolumn(df_rename,drop_cols)\n",
        "df = trimcolumns(df_rename)\n",
        "key_columns=['employee_id','employee_name']\n",
        "data_columns = intersection(df.columns,key_columns)\n",
        "df_hash = createhashkeys(df,key_columns,data_columns)\n",
        "df_hash.show()\n",
        "df_hash.withColumn('currentdatetime',from_utc_timestamp(current_timestamp(),'IST')).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm1pN3-dBz0U",
        "outputId": "4c1e6db7-6229-4100-c1ee-95495f554f42"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+-------------+---------------+--------------------+--------------------+\n",
            "|employee_id|employee_name|employee_city|employee_salary|            key_hash|           data_hash|\n",
            "+-----------+-------------+-------------+---------------+--------------------+--------------------+\n",
            "|          2|        Peter|    Melbourne|         550000|31f8febc6f6d93377...|4c9522e77f5b223d0...|\n",
            "|          5|       Jessie|     Brisbane|         420000|a89416a9523476f9a...|0512fb7cdab8814d4...|\n",
            "+-----------+-------------+-------------+---------------+--------------------+--------------------+\n",
            "\n",
            "+-----------+-------------+-------------+---------------+--------------------+--------------------+--------------------+\n",
            "|employee_id|employee_name|employee_city|employee_salary|            key_hash|           data_hash|     currentdatetime|\n",
            "+-----------+-------------+-------------+---------------+--------------------+--------------------+--------------------+\n",
            "|          2|        Peter|    Melbourne|         550000|31f8febc6f6d93377...|4c9522e77f5b223d0...|2024-01-06 20:29:...|\n",
            "|          5|       Jessie|     Brisbane|         420000|a89416a9523476f9a...|0512fb7cdab8814d4...|2024-01-06 20:29:...|\n",
            "+-----------+-------------+-------------+---------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}